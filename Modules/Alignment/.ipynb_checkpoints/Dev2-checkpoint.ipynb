{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpcful packages to load\n",
    "import os \n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "import math\n",
    "import PIL\n",
    "from collections import namedtuple, OrderedDict\n",
    "import io\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "%matplotlib inline\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Shodor\\\\project\\\\xray\\\\Modules\\\\Alignment'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-object-detection-api==0.1.0 --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR)\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "#!git clone https://github.com/tensorflow/models/archive/v2.2.0.zip\n",
    "# !wget  https://github.com/tensorflow/models/archive/v2.2.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -y install protobuf-compiler\n",
    "!pip install Cython\n",
    "!pip install pillow\n",
    "!pip install lxml\n",
    "!pip install jupyter\n",
    "!pip install matplotlib\n",
    "!pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR+\"/models/research/\")\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "os.environ['PYTHONPATH'] += ':/kaggle/working/models/research/:/kaggle/working/models/research/slim/:/kaggle/working/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test if set up is successful\n",
    "!python ./models/research/object_detection/builders/model_builder_test.py\n",
    "# !python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROOT_DIR+'/labelmap.pbtxt', 'w+') as the_file:\n",
    "    the_file.write('item\\n')\n",
    "    the_file.write('{\\n')\n",
    "    the_file.write('id :{}'.format(int(1)))\n",
    "    the_file.write('\\n')\n",
    "    the_file.write(\"name :'{0}'\".format('ship'))\n",
    "    the_file.write('\\n')\n",
    "    the_file.write('}\\n')\n",
    "    the_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "def generate_xml(imageId):\n",
    "    annotation = ET.Element(\"annotation\")\n",
    "    ET.SubElement(annotation, \"folder\").text = \"train_v2\"\n",
    "    ET.SubElement(annotation, \"filename\").text = imageId\n",
    "    source = ET.SubElement(annotation, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "    size = ET.SubElement(annotation, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = \"768\"\n",
    "    ET.SubElement(size, \"height\").text = \"768\"\n",
    "    ET.SubElement(size, \"depth\").text = \"3\"\n",
    "    ET.SubElement(annotation, \"segmented\").text = \"0\"\n",
    "    \n",
    "    boxes = get_all_boxes(imageId)\n",
    "    for b in boxes:\n",
    "        object1 = ET.SubElement(annotation, \"object\")\n",
    "        ET.SubElement(object1, \"name\").text = \"ship\"\n",
    "        ET.SubElement(object1, \"name\").text = \"ship\"\n",
    "        ET.SubElement(object1, \"pose\").text = \"Unspecified\"\n",
    "        ET.SubElement(object1, \"truncated\").text = \"0\"\n",
    "        ET.SubElement(object1, \"difficult\").text = \"0\"\n",
    "        bndbox = ET.SubElement(object1, \"bndbox\")\n",
    "        xmin, ymin, xmax, ymax = b\n",
    "        ET.SubElement(bndbox, \"xmin\").text = str(xmin)\n",
    "        ET.SubElement(bndbox, \"ymin\").text = str(ymin)\n",
    "        ET.SubElement(bndbox, \"xmax\").text = str(xmax)\n",
    "        ET.SubElement(bndbox, \"ymax\").text = str(ymax)\n",
    "\n",
    "    tree = ET.ElementTree(annotation)\n",
    "    tree.write(\"test.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe for TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "###############################################DEBUG\n",
    "for x in train_df['ImageId'][:100]:\n",
    "    boxes = get_all_boxes(x)\n",
    "    for b in boxes:\n",
    "        xmin, ymin, xmax, ymax = b\n",
    "        data.append((x, 768, 768, 'ship', xmin, ymin, xmax, ymax))\n",
    "columns_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "TFRcords_df = pd.DataFrame(data=data, columns=columns_name)\n",
    "TFRcords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A naive way to split for code testing\n",
    "\n",
    "train_set = TFRcords_df[0:20]\n",
    "valid_set = TFRcords_df[21:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from models.research.object_detection.utils import dataset_util\n",
    "from models.research.object_detection.utils import label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group data and return the same\n",
    "# Group by imagefile name\n",
    "def make_groups(df, field=None):\n",
    "    if field==None:\n",
    "        field = 'filename'\n",
    "\n",
    "    data = namedtuple('object', ['filename', 'info'])\n",
    "    grouped = df.groupby(field)\n",
    "\n",
    "    grouped_data = []\n",
    "    for filename, x in zip(grouped.groups.keys(), grouped.groups):\n",
    "        grouped_data.append(data(filename, grouped.get_group(x)))\n",
    "\n",
    "    return grouped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tf record sample\n",
    "def create_tf_example(group, img_path, label_map_dict):\n",
    "    # Read the imagefile. This will be used in features later \n",
    "    with tf.io.gfile.GFile(os.path.join(img_path, '{}'.format(group.filename)), 'rb') as f:\n",
    "        img_file = f.read()\n",
    "\n",
    "        # Encode to bytes and read using PIL. Could be done directly too\n",
    "        encoded_img = io.BytesIO(img_file)\n",
    "        # Read the image using PIL\n",
    "        img = Image.open(encoded_img)\n",
    "        width, height = img.size\n",
    "\n",
    "      # Encode the name of the img file\n",
    "        filename = group.filename.encode('utf8')\n",
    "\n",
    "      # Define the format of the image file\n",
    "        img_format = b'jpg'   # The name will be in bytes\n",
    "\n",
    "\n",
    "      # Define the variables that you need as features\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "\n",
    "      # Iterate over the namedtuple object\n",
    "        for index, row in group.info.iterrows():\n",
    "            xmins.append(row['xmin'] / width)   # store normalized values for bbox\n",
    "            xmaxs.append(row['xmax'] / width)\n",
    "            ymins.append(row['ymin'] / height)\n",
    "            ymaxs.append(row['ymax'] / height)\n",
    "            classes_text.append(row['class'].encode('utf8'))\n",
    "            classes.append(label_map_dict[row['class']])\n",
    "\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "          'image/height': dataset_util.int64_feature(height),\n",
    "          'image/width': dataset_util.int64_feature(width),\n",
    "          'image/filename': dataset_util.bytes_feature(filename),\n",
    "          'image/source_id': dataset_util.bytes_feature(filename),\n",
    "          'image/encoded': dataset_util.bytes_feature(img_file),\n",
    "          'image/format': dataset_util.bytes_feature(img_format),\n",
    "          'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "          'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "          'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "          'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "          'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "          'image/object/class/label': dataset_util.int64_list_feature(classes),}))\n",
    "\n",
    "        return tf_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFRecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where all the images are present\n",
    "img_path = DATA_DIR + 'train_v2'\n",
    "# Label map\n",
    "label_map_dict = label_map_util.get_label_map_dict(ROOT_DIR + '/labelmap.pbtxt')\n",
    "\n",
    "writer = tf.compat.v1.python_io.TFRecordWriter('./train.record')\n",
    "\n",
    "# create groups in the df. One image may contain several instances of an object hence the grouping thing\n",
    "img_groups = make_groups(train_set, field='filename')\n",
    "# Iterate over the samples in each group create a TFRecord\n",
    "for group in img_groups:\n",
    "    tf_example = create_tf_example(group, img_path, label_map_dict)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "# close the writer\n",
    "writer.close()\n",
    "print(\"TFRecords for training data  created successfully\")\n",
    "\n",
    "\n",
    "writer = tf.compat.v1.python_io.TFRecordWriter('./valid.record')\n",
    "# create groups \n",
    "img_groups = make_groups(valid_set, field='filename')\n",
    "# Iterate over the samples in each group create a TFRecord\n",
    "for group in img_groups:\n",
    "    tf_example = create_tf_example(group, img_path, label_map_dict)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "# close the writer\n",
    "writer.close()\n",
    "print(\"TFRecords for validation data created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp /kaggle/working/models/research/object_detection/samples/configs/ssd_inception_v2_coco.config /kaggle/working\n",
    "\n",
    "#!cp /kaggle/working/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config /kaggle/working\n",
    "!cp /kaggle/working/models/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz\n",
    "#!wget download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz\n",
    "#!wget download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n",
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xzf ssd_inception_v2_coco_2017_11_17.tar.gz\n",
    "#!tar -xzf faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz\n",
    "!tar -xzf faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv ssd_inception_v2_coco_2017_11_17 mymodel\n",
    "#!mv faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8 mymodel\n",
    "!mv faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8 mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Cython\n",
    "!git clone https://github.com/pdollar/coco.git\n",
    "os.chdir('coco/PythonAPI')\n",
    "!make\n",
    "!make install\n",
    "!python setup.py install\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Configure the model config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configures the .config automatically\n",
    "#fin = open(\"ssd_inception_v2_coco.config\", \"rt\")\n",
    "#fin = open(\"faster_rcnn_inception_v2_coco.config\", \"rt\")\n",
    "fin = open(\"faster_rcnn_inception_resnet_v2_atrous_coco.config\", \"rt\")\n",
    "\n",
    "fout = open(\"configfile.config\", \"wt\")\n",
    "\n",
    "\n",
    "for line in fin:\n",
    "    if 'num_classes:' in line:\n",
    "        fout.write('\\t\\tnum_classes: 1\\n')\n",
    "    else:\n",
    "        line = line.replace('PATH_TO_BE_CONFIGURED/model.ckpt', '/kaggle/working/mymodel/model.ckpt')\n",
    "        line = line.replace('PATH_TO_BE_CONFIGURED/mscoco_train.record-?????-of-00100', '/kaggle/working/train.record')\n",
    "        line = line.replace('PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt', '/kaggle/working/labelmap.pbtxt')\n",
    "        line = line.replace('PATH_TO_BE_CONFIGURED/mscoco_val.record-?????-of-00010','/kaggle/working/valid.record')\n",
    "        line = line.replace('num_steps: 200000','num_steps: 5000')\n",
    "        fout.write(line)\n",
    "\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoints\n",
    "!cp /kaggle/working/models/research/object_detection/legacy/train.py /kaggle/working\n",
    "!cp /kaggle/working/models/research/object_detection/legacy/eval.py /kaggle/working\n",
    "!cp /kaggle/working/models/research/object_detection/export_inference_graph.py /kaggle/working\n",
    "!cp /kaggle/working/models/research/object_detection/model_main.py /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"Output_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the training\n",
    "# import tensorflow.compat.v2 as tf\n",
    "# !python train.py --logtostderr --train_dir=/kaggle/working/checkpoints/ --pipeline_config_path=/kaggle/working/configfile.config\n",
    "!python model_main.py  --logtostderr --model_dir=/kaggle/working/Output_point/ --pipeline_config_path=/kaggle/working/configfile.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(\"/kaggle/working/checkpoints/\")\n",
    "os.listdir(\"/kaggle/working/Output_point/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path /kaggle/working/configfile.config --trained_checkpoint_prefix ./Output_point/model.ckpt-50 --output_directory /kaggle/working/trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al /kaggle/working/trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -cvzf /kaggle/working/trained_model.tar /kaggle/working/trained\n",
    "# !gzip -y /kaggle/working/trained_model.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_list = os.listdir(DATA_DIR + 'test_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(DATA_DIR + \"sample_submission_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of the strings that is used to add correct label for each box.\n",
    "# PATH_TO_LABELS = '/kaggle/working/labelmap.pbtxt'\n",
    "# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clmpc(label_map, max_num_classes,use_display_name=True):\n",
    "    categories = []\n",
    "    list_of_ids_already_added = []\n",
    "    if not label_map:\n",
    "        label_id_offset = 1\n",
    "        for class_id in range(max_num_classes):\n",
    "            categories.append({\n",
    "                'id': class_id + label_id_offset,\n",
    "                'name': 'category_{}'.format(class_id + label_id_offset)})\n",
    "        return categories\n",
    "    for item in label_map.item:\n",
    "        if not 0 < item.id <= max_num_classes:\n",
    "#             logging.info('Ignore item %d since it falls outside of requested ''label range.', item.id)\n",
    "            continue\n",
    "        if use_display_name and item.HasField('display_name'):\n",
    "            name = item.display_name\n",
    "        else:\n",
    "            name = item.name\n",
    "        if item.id not in list_of_ids_already_added:\n",
    "            list_of_ids_already_added.append(item.id)\n",
    "            categories.append({'id': item.id, 'name': name})\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'trained'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = '/kaggle/working/labelmap.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = clmpc(label_map,max_num_classes=NUM_CLASSES)\n",
    "\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clmpc(label_map, max_num_classes,use_display_name=True):\n",
    "    categories = []\n",
    "    list_of_ids_already_added = []\n",
    "    if not label_map:\n",
    "        label_id_offset = 1\n",
    "        for class_id in range(max_num_classes):\n",
    "            categories.append({\n",
    "                'id': class_id + label_id_offset,\n",
    "                'name': 'category_{}'.format(class_id + label_id_offset)})\n",
    "        return categories\n",
    "    for item in label_map.item:\n",
    "        if not 0 < item.id <= max_num_classes:\n",
    "#             logging.info('Ignore item %d since it falls outside of requested ''label range.', item.id)\n",
    "            continue\n",
    "        if use_display_name and item.HasField('display_name'):\n",
    "            name = item.display_name\n",
    "        else:\n",
    "            name = item.name\n",
    "        if item.id not in list_of_ids_already_added:\n",
    "            list_of_ids_already_added.append(item.id)\n",
    "            categories.append({'id': item.id, 'name': name})\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = '../input/airbus-ship-detection/test_v2/'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR,i ) for i in test_df['ImageId'][10:20]]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in ['num_detections', 'detection_boxes', 'detection_scores','detection_classes', 'detection_masks']:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                    # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "          # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "        if 'detection_masks' in output_dict:\n",
    "            output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import visualization_utils as vis_util\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
